{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    data = []\n",
    "    with open(path,\"r\") as infile:\n",
    "        lines = infile.readlines()\n",
    "        data = [ line.strip().split() for line in lines]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_data(data,mapped_entity,mapped_relation):\n",
    "    mapped_data=[]\n",
    "    for line in data:\n",
    "        mapped_data.append([mapped_entity[line[0]],mapped_relation[line[1]],mapped_entity[line[2]]])\n",
    "    return mapped_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_entity_names(path):\n",
    "    entity_names = {}\n",
    "    with open(path,\"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            content = line.split()\n",
    "            if content[0] in entity_names:\n",
    "                raise \"Entity duplicated\"\n",
    "            entity_names[content[0]] = ' '.join(content[1:-2])\n",
    "    return entity_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_pkl(filename):\n",
    "    with open(filename,\"rb\") as f:\n",
    "        pkl_dict = pickle.load(f)\n",
    "    return pkl_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_inverse_dict(mydict):\n",
    "    inverse_dict = {}\n",
    "    for k in mydict.keys():\n",
    "        if mydict[k] in inverse_dict:\n",
    "            raise \"Cannot Construct inverse dictionary, as function not one-one\"\n",
    "        inverse_dict[mydict[k]] = k\n",
    "    return inverse_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "distmult_dump = read_pkl('../symbolic/distmult_dump_norm.pkl')\n",
    "test_data = read_data('../data/fb15k/test.txt')\n",
    "mapped_test_data = map_data(test_data,distmult_dump['entity_to_id'],distmult_dump['relation_to_id'])\n",
    "entity_names = read_entity_names('../data/fb15k/entity_mid_name_type_typeid.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getRank(arr,elem):\n",
    "    coun=0\n",
    "    for val in arr:\n",
    "        if(elem<val):\n",
    "            coun+=1    \n",
    "    return coun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def analyze(table_dump,test_data):\n",
    "    rv = []\n",
    "    rv1 = []\n",
    "    missing = 0\n",
    "    for i,points in enumerate(test_data):\n",
    "        key=(points[0],points[1])\n",
    "        if(key in table_dump):\n",
    "            this_table = table_dump[key]\n",
    "            if points[2] in this_table:\n",
    "                without_zeros=np.array(list(map(lambda x: x[0],this_table.values())))\n",
    "                v,minv, maxv = (this_table[points[2]], min(without_zeros), max(without_zeros))\n",
    "            \n",
    "                #if v[0] >= (minv + (maxv - minv)*0):\n",
    "                print(v,minv,maxv,len(without_zeros))\n",
    "                rv.append(i)\n",
    "                rv1.append([points,v,minv,maxv,len(without_zeros)])\n",
    "            else:\n",
    "                #print('f****')\n",
    "                missing += 1\n",
    "        #\n",
    "    return (rv,rv1,missing)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table_dump = read('./logs/20-10-2018-1800/4.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_root='../data/fb15k'\n",
    "test_data = read_data(os.path.join(dataset_root,\"test.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data2=test_data[1:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data2i=map_data(test_data2,distmult_dump['entity_to_id'],distmult_dump['relation_to_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eid,explained,missing = analyze(table_dump['table'],test_data2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explained[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_dump['table'][(8663, 307)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id_to_relation = {}\n",
    "for k in distmult_dump['relation_to_id'].keys():\n",
    "    id_to_relation[distmult_dump['relation_to_id'][k]] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id_to_entity = {}\n",
    "for k in distmult_dump['entity_to_id'].keys():\n",
    "    id_to_entity[distmult_dump['entity_to_id'][k]] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_entity[11897]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_relation[105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_relation[152]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(table_dump['table'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(table_dump['table'][(2,1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
